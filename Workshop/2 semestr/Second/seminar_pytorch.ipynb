{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrwnHybjnXgk"
   },
   "source": [
    "# Hello, pytorch\n",
    "\n",
    "![img](https://pytorch.org/tutorials/_static/pytorch-logo-dark.svg)\n",
    "\n",
    "__This notebook__ will teach you to use pytorch low-level core. You can install it [here](http://pytorch.org/). For high-level interface see the next notebook.\n",
    "\n",
    "__Pytorch feels__ differently than tensorflow/theano on almost every level. TensorFlow makes your code live in two \"worlds\" simultaneously:  symbolic graphs and actual tensors. First you declare a symbolic \"recipe\" of how to get from inputs to outputs, then feed it with actual minibatches of data.  In pytorch, __there's only one world__: all tensors have a numeric value.\n",
    "\n",
    "You compute outputs on the fly without pre-declaring anything. The code looks exactly as in pure numpy with one exception: pytorch computes gradients for you. And can run stuff on GPU. And has a number of pre-implemented building blocks for your neural nets. [And a few more things.](https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)\n",
    "\n",
    "And now we finally shut up and let pytorch do the talking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nglvduIynXg0",
    "outputId": "15b1371a-8fc2-47a4-e5b8-86ea926fbe30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "# if running in colab, execute this:\n",
    "# !wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall19/week02_autodiff/notmnist.py -O notmnist.py\n",
    "# !pip3 install torch==1.0.0 torchvision\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fxs_Mr-VnXhO",
    "outputId": "1e01d343-2ccf-4f46-8d70-59e65e5bd7ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "\n",
      "X.shape : (4, 4)\n",
      "\n",
      "add 5 :\n",
      "[[ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "\n",
      "X*X^T  :\n",
      "[[ 14  38  62  86]\n",
      " [ 38 126 214 302]\n",
      " [ 62 214 366 518]\n",
      " [ 86 302 518 734]]\n",
      "\n",
      "mean over cols :\n",
      "[ 1.5  5.5  9.5 13.5]\n",
      "\n",
      "cumsum of cols :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  6  8 10]\n",
      " [12 15 18 21]\n",
      " [24 28 32 36]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n%s\\n\" % x)\n",
    "print(\"X.shape : %s\\n\" % (x.shape,))\n",
    "print(\"add 5 :\\n%s\\n\" % (x + 5))\n",
    "print(\"X*X^T  :\\n%s\\n\" % np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\\n\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\\n\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tjfy16EnXhc",
    "outputId": "3e7d25c9-5120-44f0-d3e2-c07c0c548422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "X.shape : torch.Size([4, 4])\n",
      "\n",
      "add 5 :\n",
      "tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20.]])\n",
      "X*X^T  :\n",
      "tensor([[ 14.,  38.,  62.,  86.],\n",
      "        [ 38., 126., 214., 302.],\n",
      "        [ 62., 214., 366., 518.],\n",
      "        [ 86., 302., 518., 734.]])\n",
      "mean over cols :\n",
      "tensor([ 1.5000,  5.5000,  9.5000, 13.5000])\n",
      "cumsum of cols :\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arcades/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# pytorch world\n",
    "\n",
    "#x = torch.arange(16).reshape(4, 4)\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)  # or torch.arange(0,16).view(4,4)\n",
    "                                        # .to('cuda:0') for asseting on gpu\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"X.shape : %s\\n\" % (x.shape,))\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n%s\" % torch.matmul(x, x.transpose(1, 0)))  # short: x.mm(x.t())\n",
    "print(\"mean over cols :\\n%s\" % torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n%s\" % torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwSOVIGZnXht"
   },
   "source": [
    "## NumPy and Pytorch\n",
    "\n",
    "As you can notice, pytorch allows you to hack stuff much the same way you did with numpy. No graph declaration, no placeholders, no sessions. This means that you can _see the numeric value of any tensor at any moment of time_. Debugging such code can be done with by printing tensors or using any debug tool you want (e.g. [gdb](https://wiki.python.org/moin/DebuggingWithGdb)).\n",
    "\n",
    "You could also notice the a few new method names and a different API. So no, there's no compatibility with numpy [yet](https://github.com/pytorch/pytorch/issues/2228) and yes, you'll have to memorize all the names again. Get excited!\n",
    "\n",
    "![img](http://i0.kym-cdn.com/entries/icons/original/000/017/886/download.jpg)\n",
    "\n",
    "For example, \n",
    "* If something takes a list/tuple of axes in numpy, you can expect it to take *args in pytorch\n",
    " * `x.reshape([1,2,8]) -> x.view(1,2,8)`\n",
    "* You should swap _axis_ for _dim_ in operations like mean or cumsum\n",
    " * `x.sum(axis=-1) -> x.sum(dim=-1)`\n",
    "* most mathematical operations are the same, but types an shaping is different\n",
    " * `x.astype('int64') -> x.type(torch.LongTensor)`\n",
    "\n",
    "To help you acclimatize, there's a [table](https://github.com/torch/torch7/wiki/Torch-for-Numpy-users) covering most new things. There's also a neat [documentation page](http://pytorch.org/docs/master/).\n",
    "\n",
    "Finally, if you're stuck with a technical problem, we recommend searching [pytorch forumns](https://discuss.pytorch.org/). Or just googling, which usually works just as efficiently. \n",
    "\n",
    "If you feel like you almost give up, remember two things: __GPU__ an __free gradients__. Besides you can always jump back to numpy with x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJ09GJh8nXhx"
   },
   "source": [
    "### Warmup: trigonometric knotwork\n",
    "_inspired by [this post](https://www.quora.com/What-are-the-most-interesting-equation-plots)_\n",
    "\n",
    "There are some simple mathematical functions with cool plots. For one, consider this:\n",
    "\n",
    "$$ x(t) = t - 1.5 * cos( 15 t) $$\n",
    "$$ y(t) = t - 1.5 * sin( 16 t) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otyvFhaZnXh1"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2151e69fab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t = torch.linspace(-10, 10, steps=10000)\n",
    "\n",
    "# compute x(t) and y(t) as defined above\n",
    "x =  t - 1,5 * torch.cos(15 * t) #YOUR CODE\n",
    "y =  t - 1,5 * torch.sin(16 * t) # YOUR CODE\n",
    "\n",
    "plt.plot(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JolWNB1nXiB"
   },
   "source": [
    "if you're done early, try adjusting the formula and seing how  it affects the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xApAzXEBnXiF"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJup3ks_nXiI"
   },
   "source": [
    "## Automatic gradients\n",
    "\n",
    "Any self-respecting DL framework must do your backprop for you. Torch handles this with the `autograd` module.\n",
    "\n",
    "The general pipeline looks like this:\n",
    "* When creating a tensor, you mark it as `requires_grad`:\n",
    "    * __```torch.zeros(5, requires_grad=True)```__\n",
    "    * torch.tensor(np.arange(5), dtype=torch.float32, requires_grad=True)\n",
    "* Define some differentiable `loss = arbitrary_function(a)`\n",
    "* Call `loss.backward()`\n",
    "* Gradients are now available as ```a.grads```\n",
    "\n",
    "__Here's an example:__ let's fit a linear regression on Boston house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXaYuKs5nXiL",
    "outputId": "22a8e53b-07ac-4149-9016-ba97ea2df7cf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f4c0c09bdd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2df4wcZ5nnv8+0y3GPA+kxmc05nTg2bGSLnLEnmQUjI0S8uzG7IWEgP0yUoPyx2tydOIl4c3MMqwg7KyOGHUGyf4FyB0dOhMROHCYOXskgbIlbn2LO3pnBeIlvYfOLJsTm4g4k00naM8/90V3j6ur3rXqrun7385GsmanprnqqPP3UU8/7fZ6HmBmCIAhC/hhI2wBBEAQhHOLABUEQcoo4cEEQhJwiDlwQBCGniAMXBEHIKcuSPNill17Ka9euTfKQgiAIuefEiRO/Y+Zh9/ZEHfjatWtx/PjxJA8pCIKQe4joRdV2SaEIgiDkFHHggiAIOUUcuCAIQk4RBy4IgpBTxIELgiDkFCMVChG9AOAPABYAnGfmUSJaBWAvgLUAXgBwOzOfi9rA6Zkapg6dRq3eQIkIC8yoVsoY374eYyPVpdfdP30S3zv2EhZdvbmIgD8eXol/OzuPBWaUiHDHh67EnrGNmJ6pYfeBU6g3mgCAoUELu266BgAwdeg0flNv4HLFscLYb7ov3euD7kcQhOJDJt0I2w58lJl/59j29wBeY+ZJIpoAMMTMX/Daz+joKAeREU7P1PDFp06i0Vzo+l3ZKuErn96IsZEq7p8+ie8++5LxfgFg6/tW4afPn0PT5fEHCCgNEJoLF7Y7jxUElf1e+9K9/pbrqth/oma8H0EQigURnWDmUff2XlIonwTwSPv7RwCM9bAvJVOHTiudNwA0mguYOnQaAPDYsZcD7/vor17rct4AsMjocN7uYwVBZb/XvnSvf+zYy4H2IwhCf2DqwBnAD4noBBHd0952GTO/0v7+twAuU72RiO4houNEdPzs2bOBjPtNvWH0+4UEepr72RLkPUG3684vjE2CIBQHUwf+EWa+FsBfAPgcEX3U+Utu5WGUXoaZH2bmUWYeHR7uqgT15PJK2ej3JaJA+w2Dny1B3hN0u+78wtgkCEJxMHLgzFxrfz0D4PsAPgjgVSJaDQDtr2eiNm58+3qUrZLyd2WrhPHt6wEAd3zoysD73vq+VbAGuh3jAAFWqXO781hBUNnvtS/d6+/40JWB9iMIQn/g68CJaCURvcv+HsANAH4O4ACAu9svuxvA01EbNzZSxVc+vRFVV6RdrZQ7FvD2jG3EXVvWQOGPQQRc/Ucrl95bIsJdW9bg0b/+MKZu24RK2Vp67dCgha/fvhlTt25CtVIGuY41PVPD1snDWDdxEFsnD2N6pmZsv3tfQV6/Z2xjoP0IgtAf+KpQiOi9aEXdQEt2+D1m/jIRvQfAPgBrALyIlozwNa99BVWhREmvMrygihJBEISo0KlQjGSEUZGWA1c5XwJw55Y12DO20WgfWycPo6ZYNKxWyjg6sS0qUwVBELqIQ0aYG1TyPAbw6LMv+aZBbIIqRwRBEOKmLxy4zskyYKylDqocEQRBiJu+cOBeTtY0gg6qKBEEQYibvnDg49vXQ6cUN42ggypKBEEQ4ibRkWppMTZSxfEXX8Ojz77UUW0UNIIeG6mKwxYEITP0RQQOtLTiD+7YLBG0IAiFoW8cuCAIQtHoixQK0K0Fr9Ub+OJTJwFAonBBEHJJ30TgQVu7CoIgZJ1CReBe5fJSiCMIQtEoTARup0hq9QYYF1IkdqWlFOIIglA0ChOB+6VI5t853/UeKcQRBCHPFMaB61IhdiTudu6VsoXdN18jC5iCIOSWwqRQvKbZqOZqrrxomThvQRByTWEcuK5XiW6eZK3eMBrKIAiCkFUK48B1vUqqHouU7oVOQRCEPFGYHDig71WiyoHb2Audkk4RBCFvFMqBq7Ad89Sh08qJOoBowQVByCeFc+C6Yp6xkap2LJpowQVByCOFcuCqfifjT85h94FTeL3RxCVlC1aJ0Fy4sLApWnBBEPJKYRYxAXUxT3OBUW80wQDqjSbAwNCgJS1lBUHIPYWKwHU5bifNRcbg8mWY+dINCVgkCIIQH4Vy4CUire7bSVKLll7NtQRBEHqlUA7cxHkDySxaSv9xQRDiplA5cK+iHRtrgBJZtJT+44IgxE2hHPj49vWwSrr58y0uXpFMDxTpPy4IQtwUyoEDAHyyKPX5ZiJmSP9xQRDiplAOfOrQaTQXvT14Ug5U11xLNOeCIERFbhcxVQoPv/REkg7UWcIvKhRBEOKA2FC5EQWjo6N8/PjxnvfjVngALed80bKBVrGOgqrGgYrUTxCErENEJ5h51L09lxG4TuGxwhpA2Sp1OXZdtaVI/QRByDO5zIHrUiX1+aayJ7jOGYvUTxCEPJPLCPzySlnbVVDXE1yFSP0EQcgzuYzAo1J4iNRPEIQ8k0sHrhufFjRvLVI/QRDyjHEKhYhKAI4DqDHzJ4hoHYDHAbwHwAkAn2Xmd+Ixs5sgqRKvfQAi9RMEIZ8EyYF/HsAvALy7/fNXATzIzI8T0TcB/BWAb0RsX+xEcSPwQ6SKgiDEgVEKhYiuAHAjgP/e/pkAbAPwZPsljwAYi8PAvGNLFWv1BhgXpIrTM7W0TRMEIeeY5sAfAvBfASy2f34PgDozn2///GsAypCSiO4houNEdPzs2bM9GZtHRKooCEJc+DpwIvoEgDPMfCLMAZj5YWYeZebR4eHhMLvINSJVFAQhLkxy4FsB3ExEfwlgBVo58H8AUCGiZe0o/AoAkhNQ4KVZFwRB6AXfCJyZv8jMVzDzWgCfAXCYme8EcATAre2X3Q3g6disjJjpmRq2Th7GuomD2Dp5ONZ8tEgVBUGIi1504F8A8DdE9Eu0cuLfisakeEl6UTEqzbogCIKbXHYj7IWtk4eVKY1qpYyjE9tSsEgQBMGbQnUj7AXd4mGt3sDWycOi1RYEITfkspS+F3SLhwSIVlsQhFxROAfut0CpWlQkdI/SFK22IAhZp1AOXLVAuXPvLNY6nLlqUVG3ClCrNyQKFwQhsxQqB66qerSds3vajjO/rVvYBIDxJ+aW3iMIgpAlChWB+1U36tIiqrSKTXORsfvAqUjsEwRBiJJCOXCT6kaVk7fTKjp0g5IFQRDSpDAOfHqmhjffPu/7Op2TTzpFkmQ1qCAIxaQQOXD3dHkdfiXsQ4MWzs13R9tEWFoANbHFr/e32153fj7MPgVB6D8KEYGrFi8BoFK2ApWw77rpGlgl6trODCNduF+Zvh1137t31rjFrPQTFwRBRyEicN3i5euNJmZ33WC8H9u537dvDguuFgO2g/W6Afj1/vZ7SlCdh9c+JQoXhP6mEA68l5atdnqiVm+gRNTluJ34qVy8en/rnhL87JV+4oIg6ChECiVsy1ZnegKAp/MG9DcEOzWie/fllbKvw9XZqzum9BMXBKEQDjxsy1aTqNhG52DdNwHd+7wcrpe90k9cEAQduUmh+CkxTKbLu/ehc7oqVljqe53XTaDqstOdAy9bJd8bjf07UaEIguAmFw48qOzOdB9BODffVB5TlxohoKO/eC+O2OTmJAhC/5ELBx6FEiNIukSH6pgVjXa8Mmh1bRNHLAhClOQiBx6FEiMq1YZ7P7p1zwQHHQmC0KfkIgKPYrJ70Jy3qke46piva/qk6LaHRaoxBUFwk4sIPAolhmof1gApKy+HBi3cuWWN0TGTkPlJNaYgCCpyEYGbLACaqFRU+/Da7+hVq3yj3us3DOPRZ1/qiNajlvlJNaYgCCoKMZVe1cxKJ9Gbnqlh94FTSy1ihwYt7LrpGgBmChFn5aYqzUIA7tyyBnvG9O1pg7Ju4qAynUMAnp+8MbLjCIKQTQo9ld40Qp2eqWH8iTk0Fy+4w3PzTdy7d7bjvTqZovtGoXKqDODIc2c97Q2az45iDUAQhOJRCAduqlKZOnS6w3l74WxCZTvbAZ9eKX72AOE07ePb1yufMKQaUxD6m1wsYvphupAYVEpoO1d78dDEeXvZA/h3LFQRtlWAIAjFphARuC5CvX7DMLZOHl5KVVxStgKNRysRBS7+8YqMp2dqWimj381FioAEQXBTCAduOzbn4uQAAXt/+vJSyqRWb8AqEQYALBrss2yVAjvvAeqMplX5cx2SzxYEISiFSKHYvH3+gmt+852Frnx3c4FxyaCFSrm7zB1oqTqACymKqo9TLVHrHZWyBatEsA+n0ml7lfJLPlsQhDAUxoGb9jo5N9/E640mqpUy7tqypiOv/OCOzXhh8salJlReQ5KrlTK+dvsmVCtl1BtNNBfUE3xsvFIkks8WBCEMhUihAMEWKO1qxv0navjKp1t67alDp7Fz7yymDp3G9RuGsf9EzTNivn7DcKARaTopYLVSFuctCEIoChOBh8khN5oL+OJTP8POvbMdZerfffYlzx7fX/n0Rhx57mygEWkymEEQhKgpjANX9jopEbo7nXTSaC5qR6G5sXt8j41UA49IS0sKaI97WzdxEFsnD0v/FEEoEIVJoeh6nex0VVn2gjOi9upu6J7E47QxyXRJFIMwejm2dE8UhHgpjAMH1A7S7lvSK+6IWqc9z9KCZFpNsNK8cQhCP1GYFIoOVWolKCWiLsccdUokjlRHFIMwwhCm2lQQhOD4RuBEtALATwBc1H79k8y8i4jWAXgcwHsAnADwWWZ+J05jw6BKrQSJyL2ialXEr0oduI+vaoUbR8SaVhOstG4cgtBv+LaTJSICsJKZ3yAiC8A/Afg8gL8B8BQzP05E3wQwx8zf8NpXXO1kg7J18rCRE9flsnVMz9Qw/uRchya8NNCq/nQWFblvCjp7qpVyx2DkoKja7NotcIOeWxDiOh9B6Fd07WR9Uyjc4o32j1b7HwPYBuDJ9vZHAIxFZGtk6NIS49vX+6pTbGcTxME98MyproKehUXuqgg1LfLpNWJ1pnmAzjFxplN9wqR2RDIpCMlglAMnohIRzQI4A+BHAH4FoM7MdqnirwEoPR0R3UNEx4no+Nmz3n2yo8RrDNnYSNVTOkjAUiOsII5LNZ1eh7vIR0UUqY6xkSqOTmxDtVLuOme/vHTYUW7SPVEQksFIhcLMCwA2E1EFwPcBbDA9ADM/DOBhoJVCCWNkGPwUGEODltbhMtBRiRmHimKACOsmDuLySllZ+Rl1xBomyu9FxSLdEwUhfgKpUJi5DuAIgA8DqBCRfQO4AkCmKkS8HNb0TA1vvKXvcwIglIpC1yRLxQJzR0n/LddVY41Yw0T5shgpCNnGRIUyDKDJzHUiKgP4cwBfRcuR34qWEuVuAE/HaWhQvBQYQSbzOKnVG9g6eVirLNl98zVdI9vclBRTfRrNBRx57qzvAl8vxTFhpvrIKDdByDYmKZTVAB4hohJaEfs+Zv4BEf0LgMeJaA+AGQDfitHOwHhNi++lOrNWb2D8iTmAsLRgWas3sHPvLBitKFw3NIIALGpUP86oVidF7EVqqKtU9XqvjHIThGxTiKn0bnTyOXtavKmMMCyqafU2qggcuKB68ZL+qYhbmicl8YKQPoWeSu9GtfjmnBaviiyjhKF3uirn7Yxqdbbr6CUfbeKcZTFSELJLIR243+KbM50QVyRuF8vo9l8iwiJzl+MM6pDD5qOlX4kg5J9C9kIxUVw49dFBsQYIVsm7FKhE5OmMF5nxfHv6j9NhBnXI8++cD9U3RfqVtJB2u0KeKaQDD1IJGDTirVbKmLptE6Zu3dRR4ejGlgnq0DnqoM23zs03jYpr3IhEMHyhkiBkhUKmUIIoLoI0tyoRdezH/urMJQ9oFimdeCk5wqR3wrSI7TeJoCrfn1a7XUGIikKqUIKgUn1YJQIYSj23X8/vdRMHfcv0bTWMCWsnDhq9jgA8P3mj0WsB9XlnrZ95VOjOVbeIHfRaCkLc9JUKJQi2s3rgmVNLpfUrly/DJzatxmPHXlYW3dzbHn6sKuipeJToA63FzceOvYzRq1YZOUqvhVAnQSPnMLrwvKKLtHWSzqI+hQjFo+8duM1bzcWl7+uNJvafqHmmQmr1BsafnOuI1Gv1xtICp7sroZMF5i7Fh07SZyJ5DFtc06tEMC8acV1ef4G5KxKXQiUhTxRyETMoXhGaF82F7laxzUXGsgHyVbc4FR9+nRO/8umNWltU04KSIE8LgLqI2u45I10ThbwiDhz+EVpQGs1FjG9fj4d2bPZ8v31cP0nf2EhVW4K/yJyKw8mTDNFLlWTLSVWSTkHIOuLAYRahBcVWMnhFz/ZxTSR9cfYMD0OeZIjSn1woKpIDh3fTJjtPrFOr6HLd7qpPr6ZQJpK+rDWWypsMUVoCCEVEInCYR2gXLbtwuYYGLUzduglDg+oe4O6qT6/9mxQeZS2KlLFpgpA+fa8D1+FUWFQGLbzx1vnAPcTdg4O9VBtev7t/+mRHa9wkBhObkBcViiDkHZ0OvPAOPIyTUaVLwmKVCCuXL0O90ezqUGhSOHP/9El899mXtL/PijMXBCE++rKQJ0zHvemZGu7bN+dbDm9Kc4GXBjzohgp7Od1HPZy3c59JdROUqFsQskOhHXjQXhe2w4/KeZugU23YjjKIJc5z00316cX5mt4QxckLQjIU2oEHlbo98Myp2IY86FCpNnpJ4fym3ujKmevGwAWN2E1uiNJnXBCSo9AOPIjUbXqm5tnDJA4IWIqMg3Y01HFJ2eqaBQqoG3M1mgt44JlTxtGyyQ1ROvwJQnIUWkYYROqWRgUhAx0ac7ssPazzLlslEHmPYHNzbr5pXA5vUkyUpwIfITpkMEY6FNqBm2qnp2dqsQ451kFoqUzu2zcXKl0yaA10nVu9x6cIr3J4kxti1ipGhfjJU1+colF4GaEfUUoGw+A1cd70/ZeULRAB9flmT+kX5z6d/bDt9E6t3uiwd2jQwq6brulYNFXdCK0SYerWTZGlUEwXSWUxNRm2Th5W/r9XK2UcndiWgkXFQycjLHQEboIqZ5skvd4+Ga32t+fmm0bplxLRUsReKaurSAeIlqInZ3Tlttduwet+jdLIiDCN9iQqTA5Jm6VH3zvwNFInaWLP6nzz7fP4xKbVym6Jdr9yO4LV3eDsdIvfTbC5yJGtMZh2QcxTt8S8I2mz9OhrBz49U1MOJM4iK5eXYEX4v1VvNLH3py/jluuqym6J9uQhvxvcb+oNo0jLS+8eZPFLt59avdGxD4kKk0P64qRHXzvwoIUyaUAA7tqyBp+6tgrH0KBIaC4yjjx3Vttr3ITLK2WjSMtL7x4kzeF1LOc+KgZNxoRoyFqjtX6i0DpwP/IQjTGAH8y9slSOHzX2Al+YVJIzyhp/ck7bWtdLuhlUM24yYq7RXMBFywZkXFqCSLvedOhrBx7WcSVNXM4baN0g5t85D2uAjLot2oOAq5Uyrt8wrFWe2Hg12QqT5nAPY9ZZ/HqjiQd3bBYVilBo+tqBm0Rz/cC5+SasEhlJGv/dJSuWoli/a6eTkfn1edGlOdyywAd3bMbuA6eUN7jLK+VYo0KRKApZQHTgGo1zFES9v7gZGrRQb8sRvbAGCBevWGbUeoCADgfnp7vXtdhVTkQaICwCWHA9OVgDhKnbotOdu1HZYtIaWBDC0pftZE1wRmlexShhuHPLGhz82SuJ91gJy7n5JsrWABo+q6XNRTY+J+fCIuCtu/dKt6jep0v5XLxiWayOVPq9CFmhr1UobuwJ5V5DjE1lh0ODFvaMbcTMl27AQzs2hxqM3CsP7diMckDtoZ/zDovt4HT5bQI8p8IHWXDutZ2AHyJRFLKCOHAFKl0rAFTKFu7csqZDLrX1fau6nDoBuPEDq5d+NrkxxMHUodNL1ZJZwM4Xq/CT9wWR/8UtFZTCFSEriANXYOta3QOL640m9p+oYXz7ejw/eSOOTmzDo3/9Ydy5ZU2HE2cA+0/UOvTM0zM1zL9zPpkTaFPzcJhxoqgLAgBUBi3lNTCR96luqtYAoTTQeTCrRLFLBaVwRcgK4sA1jI1UMbi8e4lAVY595Lmz2nFpwIVFr6Rz4SVqObOkq02Z0e1sS4Q33jrfdQ2ILlwrrwIeVbHIjg9e2f0HnMCqsRSuCFnBdxGTiK4E8D8BXIbWx+NhZv4HIloFYC+AtQBeAHA7M5+Lz9TkMc11+r0urYZZC8wYG6ni3r2ziR/7rQ6FxgAuWlZSyv1sEVSt3sDOvbO4d++sdjHTLQvcOnm4ayHT7rsStzMNI1EU6aEQNSYR+HkA9zHz+wFsAfA5Ino/gAkAP2bmqwH8uP1zoTDNdfq9Lq3FrWqlnFq/F6dbbTQXjYqR3AOaw/ZFiet69zK0QLojCnHg68CZ+RVm/uf2938A8AsAVQCfBPBI+2WPABiLy8i0MM11+r0ujTy0ffw89HtR0Wgu4L59c6H6olzevnFFOSGmVwcs3RGFOAiUAyeitQBGABwDcBkzv9L+1W/RSrGo3nMPER0nouNnz57twdTkMc11+r1Op2qJawGiRLR0/CxJ21TXwAtnW1sVuhvn9RuGI492e3XAJk8LMpZMCIpxIQ8RXQxgP4B7mfn35JAaMDMTkTLQY+aHATwMtCoxezM3eUxznV6vGxup4viLr3UNGy6VCLzAkUfId3zoyiVbstTv5do1l+B//+q1QOfrdJK6/LFdfFUiQqO5gMeOvdw12KLXQhuvNrbTMzXf/foN2HZXdzqLnyRPLugwCgKJyELLeT/KzE+1N79KRKvbv18N4Ew8JhYDlVKlucCoDFpdUWSvOesfzL2y9L0u+k+DoM7bxl7gdEbUO/fOYu3EQUwdOo3rNwyjbJWWnLZuKlEvTyNeaTCT6N4vzSYpFiEMvg6cWqH2twD8gpm/7vjVAQB3t7+/G8DT0ZtXHHTOoz7f7Eq/uHXlQak3mkuP4M70TlJc/Ucrldt7edJwv9e54Pnosy8ZqXx6WYvwuhGaOFq/NJtUdwphMEmhbAXwWQAnicjWo/0tgEkA+4jorwC8COD2eEwsBpeULaUS45KypU2/fPfZl0Ifz/0IPjZS1Q6fjZK7tqzBkeeSXeswuTH0Wmhj///oJJkmjtYrzeaXYhEEFSYqlH9iZmLmDzDz5va/f2Tm/8fMf8rMVzPznzHza0kYnFd01Ym/f6upfPzeM9ZdCRqURnMBDzxzamlh7LU33+5pfybsP1HLTM7dhgDccl3vrWXHRqraJ5leHa1UdwphkErMhNA1WFpkfQ41iqZM5+abS7njqBtV6WZpqrbHjdcRGYjsqSAuRyvVnfFSVIVP37eTTQovNYhOIZGkgsSesGOStiEAD+7YjJ2adMICc6K90K0Bwo4PXunZujeqXLJ7IlCUFZVZG0tWlMrRIit8JAJPCD81iMrBqN5jR5pRLkrak3NGr1rlGz0TWn3Ox0aqvgOGgxI6cm+/zavzom7IcRjs7pJ2Q7O8OwEVRaocLbLCRyLwhLA/5Pftm1PK3FTO0C/a81uUtAbgO8nefvy3P7A6CR5wwXnvGdsIINqRdPZEGwDYuXc20A2gucBK7beTqAZPZSkq9bOlF1uLNLSiyAofceAJYv/hq8Zx6XKoXo/Vfg704hUW3moudo0hu3jFMtTnmx0f6s0P/NDXEbtzye5CmrC4m1eFab7l5byB1pBjm7COLUuP4n629GprkZxekRU+kkJJmCgXq+x96VBpzKdu24SZL93Q8fg/PVMzajYFdH+A7XRCGMpWCQ/t2NyVhgiTHvJLv1xSbqVQekkNZOlR3M+WXm0t0tCKIit8JAJPAVVUHTYqHBupaiNg08nsQRyQ6gNsdzwMkqVw9mtxM759vTaNUilbePv8YtcTzC3XVbH/RE37FFFvNHH/9Ekcee5s6NRAlqJSP1t6tVX1dGfq9LKUZgLiXXhOG3HgGaDXx91ePmyA+Ydat88wHQ8X273KnTg/+IPLS3jznU5HW7ZK2H3zNUvHdH8YR69a5ZnOcfeicVKrN7B18rDnBzxLj+J+tvRqa1inl6U0k5OsKXyiQhx4Buh1wcjkw6aKiuz3mDhfr4nxYSJQtyNxf/DffGcBVomwcvkyvN5oojJo4a3mwlJ+fGjQwoM7NnfYY39I100cVJ4ToxX5q/LlBCw5PJ3T6fVGGSV+tkRhaxinV6TFzzwgDjwDRPFo7vVhU0VF40/MAdRScHhhDRCmbtvk+eELqlcnoMuRqD74zQXGyouWYffN12D8ibmO6Tvn5psYf3IOQHdk52XPAjPKVqnjWKr0j8rpZOlR3M+WtGzNUpqpHxAHngHifjRXOsdFs6SHyYiy8e3rMf7knO/NwMbWkTvROdxavYHdB04p7W0uqG3zyqHbTxJOx6Y7tsrpZOlRvBdb4spTZynN1A+IA88AcT+a9xr9+L1/bKSK3QdOGSlZrAHC6FWrOrb5LYJ67VflLHT91wnA9RuGlbM1gzqdrC3UufHKRQOILU+dpTRTPyAOPAPE/bjba0m+SfT0uqEMURXR9zr2bfMDPwQROrTte8Y24vmzb+Dory70WGO0mm2NXrWqp9x2VhfqnPjJCOPKU2cpzdQPEEdVombA6OgoHz9+PLHjFZkgEaDb4QDAALUaablxb3dWSHodL0irWgLw/OSNSz/rFh3DYssKdX1d7NYBTpzXszJogbl1Uwpyrqr9poXumtpqed3vnP8vQnYgohPMPOreLoU8OSRoMYqqeOjdK9S9Qd69wuoqMgLgezyvvi1u3BG9XWQTFY3mAh49pm/KpcttH53Yhgd3bMZbzUXUG03tueZhoc6rEKdIRTr9jqRQckgYqZY777tu4qDyda83mpjddQOAC1GpKtp0H0/16Hz9huGu4hpVaiKO7rNeD5ZOR+V+knnz7fO+1zYPC3V+aaEo89RZXw8oMuLAc0gUEWDQIbsmx1OpIuziGrf+3Fk0o2sBGxe2Dapctg7nueZhoc4kFx2F0w26HpCWsy/qTUYceA6JIgL0c0KqKD/M8dxOPYjTHBq0MLh8WaQ90VcuLy3Zs/vAKeNOis5zjXOhLkpH4yUzjEoOGeRpMK3F3zwsOodFHHgOiarKDtA7Ib9oPsjxnE5pQFMJqaI+38SNH1jt2eMkCFaJ8OVPbVyyyeTWoBwAAA2vSURBVLSBl+pc49Bgp+1owtw8gjwNplWlqTvuvXtnMXXodKzReNyRvzjwHBJVBOjlhLykh15l9W7cTsnUeQMXZH+3XFf1nLZjgttmrwZeduTvlfaJI+WQZhl62JtHkKfBtBZ/vfYf500yiRuyOPCcEndFoC7KD9r61iQV40WjuYDHjr2MRWYMtfuhBJ3tqZL3+TkNt/N2fxDv3TuLe/fOolK2sPvma4yviZeTjtvBeUWDYW8eQZ4G01r89auDiOsmmcQNWWSEghKV9DBM33IT5zPgo0JZYAaj1f8kqPO2SqR1JjrOzXdKCL1y5fVGE+NPzBmPGvNqGaAjCpmln/Q0SDsBJ0H+TtLqy+03zhCI5ykgiScOicAFLVFE+brop0SERWZUBi288dZ5LMZVUObarVMa6S7f1zW18nuCMOkXE8LUC3ZFILP0q8zUtTIIs1Dt9TrbliTVIM7j6m5UcTwFJPHEIQ5ciBW/VMzWycOxygibi4zdB04pnTbjguOq9thuQBVVOVMWl5St0I64HsH18YoGda0MVF0jeyWtZmD2cVXy2LieApKQm0oKRYgVv0fsKB4n/fxivdFccs5uR2U776MT27Sj3IYGLd9HcF1/cztlUW80Q9+ooojYvKovdf8HjPzL7NxElRrMyrEkAhdiJ6zaxQS778mR586G3o/9Pl3EtOum1hQgXcdFa6A7z97r4u3SvkuEN98+j3UTB3tKOXhFg7rUQpjZpHkgyaeAuI8lEbiQKiYLTG7siNuOaPaMbcTRiW14aMfmwPsCLgxEHhup4pbrqks/l4hwy3XVpQ/h7K4b8NCOzRgavLCoWClbyoEXYZ8srAHC0KAFQivyB6OjL8vOvbNYO3EQWycPGy+c2uemiwaLPPS36EgEnjBFLen1wuuc7a/37ZvTasSH2t0B7ei3Mmhh103d0j3VItn8O+d9Uxf2cadnath/orb08wJzV/tZ04jK5MnCHu9mf6208+R2W9w33z7fNcjC/imMplhne9jFxX78W84a0k42QXQLKHHl4LKA6TlPz9S6xqYBrRTCjj+5UtkUy+S6mfR0sXPgujaxqsKeKI7rxBogoxF3OtuTph//ltNE2slmAD8pVxExPeexkSqmbtuEikPzPDRoYerWTTjy3NnQ182ZOgC6FzydqQJd2uPcfNO4da/quIRWqsVOjZQUcpTmIgd23l42x00//i1nEUmhJEge+khHTZBz1j3i72xPojfdt9d+vR77TRdUTavpdOeja+UbhrRa2Pbj33IWEQeeIHnoI90LKucYxTlHed28ctgqpYaOWr2Bkb/7YccYN9PUQRDljbMjo7vYJs2FxqL/LecFSaEkSJFX+3Wl2tdvGO75nJO6biqlRsWjjN1dcm+qCjFV3tgSxqMT2/DC5I14cMfmRPTLJhT5bzlPyCJmwhR15d5rTqStNe7lnO+fPonHjr28pNq440NXYs/YxqjM1xJkMbJStrDyIrPFzumZmqfypkSEr93eLU8MQ9i/Ob/3FfVvOYvoFjHFgQuR4DVE1z0oN+gHP23Fw/RMDfdq8vBe+Nnotd+oBgyHvXZxXHNx+OEJrUIhom8T0Rki+rlj2yoi+hER/Wv761DUBgv5wnRQbtCBzED6ioexkWqoqkQ/G8dGqh1FQU6iyiWHvXZRX/Mw/++CPyY58O8A+Lhr2wSAHzPz1QB+3P5Z6GNMc6JhHEMWFA9hKkYBfxt33XRNz7nk6Zkatk4exjpFhWbYaxf1NU/7JlxUfB04M/8EwGuuzZ8E8Ej7+0cAjEVsl5AzTBv3hHEMftG9lwOLCpWu2wS/SNq936FBCxctG8DOvbNG5+IX2Zo+GZn+PuyTQRZuwkUkrIzwMmZ+pf39bwFcpnshEd0D4B4AWLNmTcjDCXnApMw8jPzMqxFTknMk3eenW7h122i63zDn4jf1JWxL06hboYrsMB56lhFyaxVUuxLKzA8z8ygzjw4PD/d6OCHnhJGfeUX3aT6aq87F3Wir1/FzvaaXwrY0jboVqsgO4yFsBP4qEa1m5leIaDWAM1EaJRSXsI2TdNF9nI/mfqqJqCfMhE0v+UW2YVuaRtkKdWykiuMvvtYhBbU7PQrhCevADwC4G8Bk++vTkVkkFJ4oHUMUj+YqRw10DzJWpTPSPhe/VIfXTShJWZ9Jp0chOL46cCJ6DMDHAFwK4FUAuwBMA9gHYA2AFwHczszuhc4uRAcuRE2veuX7p0/i0Wdf6ipRX2ENKNvQBu3+F8RJ6oqGKmXvyfe6Y3hdGwCJauu9Cr3i6qZYJN25TgfuG4Ez8x2aX/1pz1YJQo/0ksaYnql1OW/Ae5BxkNRM0EVJe9sDz5zquHnUG03f96m2++XUvRY/w+DlMJNWoSS5uJ0m0sxKyD1h0xi6Yb5eBEnN+ClEVNgLs+7oP4xzDeM0wzpUP4eZtAolzLXPI9LMSuhbvJxVpdw9yDioaiLtIhovLXfUOm+/aD9pFUq/6M4lAhf6Fl1USAB239waZNxLDjVs1Bnmfar0hd8CZ5Q6bxM5I2B+PXvNX/eL7lwicKFv0ZXHl61WJeTUodMY374ez0/eiKMT2wI/eoeNOoO+T1eNCUCr5e5F562qfDWJ6O3CossrZfym3sDUodPKStMo+qb0i+5cuhEKfY0z0qsMWnjjrc5Bwkl24HPbwgy83vAfGJGkwkOnbLnluqrv3FJTxVBU55OECiUppYu0kxUEH9KQutn0IocM0sq3V3rp+256fZM8n15Iss1xaBmhIPQLaS589aKaSDLf63WN/NRAptc3L/nrLChdJAcuCG2iVmYEoZebR5L5XpNrpOsOaXp985K/zoLSRRy4ILRJ03H0cvOIuvGUF37XyGsB0vT6Jnk+vZDmDd9GUiiC0Cbq5lRB6LV9a5Q9WfyOA+ivkVdawc5zm1zfpM6nF6JuuRsGWcQUhIwQp6IhKbVEXhYgoyJtFYpE4IKQEeKKOpPsC5KXBcioSPtJQXLgglBwkhx6kZcFyKIgEbggJECarU2TVEvocuRASwdehNauWUIcuCDETNqtTZNOa7jTCmmff5GRFIogxEyaczuB9NMaaZ9/kZEIXBBiJu2CjzTlkUD6519kxIELQsxkQZmRploiC+dfVCSFIggxk3YKI236/fzjRCJwQYiZtFMYadPv5x8nUokpCIKQcXSVmJJCEQRByCniwAVBEHKKOHBBEIScIg5cEAQhp4gDFwRByCmJqlCI6CyANwH8LrGDhudSiJ1Rkgc782AjIHZGTR7svIqZh90bE3XgAEBEx1VymKwhdkZLHuzMg42A2Bk1ebFThaRQBEEQcoo4cEEQhJyShgN/OIVjhkHsjJY82JkHGwGxM2ryYmcXiefABUEQhGiQFIogCEJOEQcuCIKQUxJz4ET0cSI6TUS/JKKJpI4bFCJ6gYhOEtEsEWWmdSIRfZuIzhDRzx3bVhHRj4joX9tfh9K0sW2Tys7dRFRrX9NZIvrLNG1s23QlER0hon8holNE9Pn29kxdUw87M3VNiWgFEf2UiObadj7Q3r6OiI61P/d7iWh5Ru38DhE977iem9O00xhmjv0fgBKAXwF4L4DlAOYAvD+JY4ew9QUAl6Zth8KujwK4FsDPHdv+HsBE+/sJAF/NqJ27AfyXtG1z2bkawLXt798F4P8CeH/WrqmHnZm6pgAIwMXt7y0AxwBsAbAPwGfa278J4D9l1M7vALg17esY9F9SEfgHAfySmf+Nmd8B8DiATyZ07ELAzD8B8Jpr8ycBPNL+/hEAY4kapUBjZ+Zg5leY+Z/b3/8BwC8AVJGxa+phZ6bgFm+0f7Ta/xjANgBPtrdn4Xrq7MwlSTnwKoCXHT//Ghn8I2zDAH5IRCeI6J60jfHhMmZ+pf39bwFclqYxPvxnIvpZO8WSeqrHCRGtBTCCVjSW2WvqshPI2DUlohIRzQI4A+BHaD1115n5fPslmfjcu+1kZvt6frl9PR8kootSNNEYWcTs5iPMfC2AvwDwOSL6aNoGmcCtZ8KsRhLfAPA+AJsBvALga+macwEiuhjAfgD3MvPvnb/L0jVV2Jm5a8rMC8y8GcAVaD11b0jZJCVuO4no3wP4Ilr2/gmAVQC+kKKJxiTlwGsArnT8fEV7W+Zg5lr76xkA30frDzGrvEpEqwGg/fVMyvYoYeZX2x+aRQD/DRm5pkRkoeUUH2Xmp9qbM3dNVXZm9ZoCADPXARwB8GEAFSKyZ+9m6nPvsPPj7VQVM/PbAP4HMnQ9vUjKgf8fAFe3V6SXA/gMgAMJHdsYIlpJRO+yvwdwA4Cfe78rVQ4AuLv9/d0Ank7RFi22Q2zzKWTgmhIRAfgWgF8w89cdv8rUNdXZmbVrSkTDRFRpf18G8Odo5euPALi1/bIsXE+Vnc85btqEVp4+9b9RExKrxGzLnB5CS5HybWb+ciIHDgARvRetqBsAlgH4XlbsJKLHAHwMrdaXrwLYBWAarVX+NQBeBHA7M6e6gKix82NoPeozWiqf/+DIM6cCEX0EwP8CcBLAYnvz36KVX87MNfWw8w5k6JoS0QfQWqQsoRUY7mPmv2t/ph5HKy0xA+CudpSbNTsPAxhGS6UyC+A/OhY7M4uU0guCIOQUWcQUBEHIKeLABUEQcoo4cEEQhJwiDlwQBCGniAMXBEHIKeLABUEQcoo4cEEQhJzy/wFkZEvEkAzT0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "plt.scatter(boston.data[:, -1], boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFGKYcrEnXiV"
   },
   "outputs": [],
   "source": [
    "w = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "x = torch.tensor(boston.data[:, -1] / 10, dtype=torch.float32)\n",
    "y = torch.tensor(boston.target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOn0bKt9nXig"
   },
   "outputs": [],
   "source": [
    "y_pred = w2 * x**2 + w * x + b\n",
    "loss = torch.mean((y_pred - y)**2)\n",
    "\n",
    "# propagete gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ek9yGHHbnXip"
   },
   "source": [
    "The gradients are now stored in `.grad` of those variables that require them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85Jp2tYTnXir",
    "outputId": "050debdc-0848-4baf-a8ad-a8d7d26096af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw = \n",
      " tensor([-47.3514])\n",
      "dL/dw = \n",
      " tensor([-68.1231])\n",
      "dL/db = \n",
      " tensor([-45.0656])\n"
     ]
    }
   ],
   "source": [
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/dw = \\n\", w2.grad)\n",
    "print(\"dL/db = \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LfTAbSZCnXi2"
   },
   "source": [
    "If you compute gradient from multiple losses, the gradients will add up at variables, therefore it's useful to __zero the gradients__ between iteratons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFPuY4OjnXi6",
    "outputId": "5e3fc667-0005-4308-96eb-c53c03a32de8"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-958b242f2df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         plt.scatter(x.data.numpy(), y_pred.data.numpy(),\n\u001b[1;32m     23\u001b[0m                     color='orange', linewidth=5)\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/arcades/.pyenv/versions/3.7.1/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2083\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 532\u001b[0;31m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(300):\n",
    "\n",
    "    y_pred = w2 * x**2 + w * x + b\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    w.data -= 0.05 * w.grad.data\n",
    "    w2.data -= 0.05 * w.grad.data\n",
    "    b.data -= 0.05 * b.grad.data\n",
    "\n",
    "    # zero gradients\n",
    "    w.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    # the rest of code is just bells and whistles\n",
    "    if (i+1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(),\n",
    "                    color='orange', linewidth=5)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVqYKi5nnXjD"
   },
   "source": [
    "__Bonus quest__: try implementing and writing some nonlinear regression. You can try quadratic features or some trigonometry, or a simple neural network. The only difference is that now you have more variables and a more complicated `y_pred`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TW_e49dNnXjG"
   },
   "source": [
    "# High-level pytorch\n",
    "\n",
    "So far we've been dealing with low-level torch API. While it's absolutely vital for any custom losses or layers, building large neura nets in it is a bit clumsy.\n",
    "\n",
    "Luckily, there's also a high-level torch interface with a pre-defined layers, activations and training algorithms. \n",
    "\n",
    "We'll cover them as we go through a simple image recognition problem: classifying letters into __\"A\"__ vs __\"B\"__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2PEbzDcnXjJ",
    "outputId": "995f7678-1b49-4208-8558-e98196df67bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Extracting ...\n",
      "Parsing...\n",
      "found broken img: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\n",
      "Done\n",
      "Train size = 2808, test_size = 937\n"
     ]
    }
   ],
   "source": [
    "from notmnist import load_notmnist\n",
    "X_train, y_train, X_test, y_test = load_notmnist(letters='AB')\n",
    "X_train, X_test = X_train.reshape([-1, 784]), X_test.reshape([-1, 784])\n",
    "\n",
    "print(\"Train size = %i, test_size = %i\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3CYE3KVnXjR",
    "outputId": "1005ea4e-4d7d-4b54-8bdf-726cc52df48c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(X_train[i].reshape([28, 28]))\n",
    "    plt.title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VX-ubGKnXjb"
   },
   "source": [
    "Let's start with layers. The main abstraction here is __`torch.nn.Module`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s75WDK_lnXjf",
    "outputId": "e830b9b5-da76-4155-982e-c8cf68bb8237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base class for all neural network modules.\n",
      "\n",
      "    Your models should also subclass this class.\n",
      "\n",
      "    Modules can also contain other Modules, allowing to nest them in\n",
      "    a tree structure. You can assign the submodules as regular attributes::\n",
      "\n",
      "        import torch.nn as nn\n",
      "        import torch.nn.functional as F\n",
      "\n",
      "        class Model(nn.Module):\n",
      "            def __init__(self):\n",
      "                super(Model, self).__init__()\n",
      "                self.conv1 = nn.Conv2d(1, 20, 5)\n",
      "                self.conv2 = nn.Conv2d(20, 20, 5)\n",
      "\n",
      "            def forward(self, x):\n",
      "                x = F.relu(self.conv1(x))\n",
      "                return F.relu(self.conv2(x))\n",
      "\n",
      "    Submodules assigned in this way will be registered, and will have their\n",
      "    parameters converted too when you call :meth:`to`, etc.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(nn.Module.__doc__) # show documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7xSkd3enXjn"
   },
   "source": [
    "There's a vast library of popular layers and architectures already built for ya'.\n",
    "\n",
    "This is a binary classification problem, so we'll train a __Logistic Regression with sigmoid__.\n",
    "$$P(y_i | X_i) = \\sigma(W \\cdot X_i + b) ={ 1 \\over {1+e^{- [W \\cdot X_i + b]}} }$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIRxMp0znXjq"
   },
   "outputs": [],
   "source": [
    "# create a network that stacks layers on top of each other\n",
    "model = nn.Sequential()\n",
    "\n",
    "# add first \"dense\" layer with 784 input units and 1 output unit.\n",
    "model.add_module('l1', nn.Linear(784, 1))\n",
    "\n",
    "# add softmax activation for probabilities. Normalize over axis 1\n",
    "# note: layer names must be unique\n",
    "model.add_module('l2', nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1-J2zqZnXjz",
    "outputId": "62afc71b-49a2-4af3-efe6-043d35f3afda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shapes: [torch.Size([1, 784]), torch.Size([1])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight shapes:\", [w.shape for w in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwuWFjmYnXj7",
    "outputId": "4312b334-9284-4193-81ce-d33b5af3abb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5262, 0.4357, 0.1259], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy data with 3 samples and 784 features\n",
    "x = torch.tensor(X_train[:3], dtype=torch.float32)\n",
    "y = torch.tensor(y_train[:3], dtype=torch.float32)\n",
    "\n",
    "# compute outputs given inputs, both are variables\n",
    "y_predicted = model(x)[:, 0]\n",
    "\n",
    "y_predicted  # display what we've got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rY5DvuxonXkD"
   },
   "source": [
    "Let's now define a loss function for our model.\n",
    "\n",
    "The natural choice is to use binary crossentropy (aka logloss, negative llh):\n",
    "$$ L = {1 \\over N} \\underset{X_i,y_i} \\sum - [  y_i \\cdot log P(y_i | X_i) + (1-y_i) \\cdot log (1-P(y_i | X_i)) ]$$\n",
    "Your task is to implement crossentropy loss __manually__ without using `torch.nn.functional`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beaCNSQVnXkG"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Loss is too large even for untrained model. Please double-check it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-158018150215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Crossentropy must non-negative, zero only for perfect prediction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m assert loss.data.numpy() <= np.log(\n\u001b[0;32m---> 11\u001b[0;31m     3), \"Loss is too large even for untrained model. Please double-check it.\"\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Loss is too large even for untrained model. Please double-check it."
     ]
    }
   ],
   "source": [
    "crossentropy =  y * torch.log(y_predicted) + (1 - y) * torch.log(1 - y_predicted)# YOUR CODE\n",
    "\n",
    "loss =  (torch.mean(-crossentropy))# YOUR CODE\n",
    "\n",
    "assert tuple(crossentropy.size()) == (\n",
    "    3,), \"Crossentropy must be a vector with element per sample\"\n",
    "assert tuple(loss.size()) == tuple(\n",
    "), \"Loss must be scalar. Did you forget the mean/sum?\"\n",
    "assert loss.data.numpy() > 0, \"Crossentropy must non-negative, zero only for perfect prediction\"\n",
    "assert loss.data.numpy() <= np.log(\n",
    "    3), \"Loss is too large even for untrained model. Please double-check it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zl0dwAG8nXkO"
   },
   "source": [
    "__Note:__ you can also find crossentropy loss in `torch.nn.functional`, just type __`F.<tab>`__. However, it operates on raw logits instead of probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0lbtDdenXkQ"
   },
   "source": [
    "__Torch optimizers__\n",
    "\n",
    "When we trained Linear Regression above, we had to manually .zero_() gradients on both our variables. Imagine that code for a 50-layer network.\n",
    "\n",
    "Again, to keep it from getting dirty, there's `torch.optim` module with pre-implemented algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yazlToRdnXkT"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "# here's how it's used:\n",
    "loss.backward()      # add new gradients\n",
    "opt.step()           # change weights\n",
    "opt.zero_grad()      # clear gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58RSjOeMnXka"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-72b2a96541b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dispose of old variables to avoid bugs later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# dispose of old variables to avoid bugs later\n",
    "del x, y, y_predicted, loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_param_group',\n",
       " 'defaults',\n",
       " 'load_state_dict',\n",
       " 'param_groups',\n",
       " 'state',\n",
       " 'state_dict',\n",
       " 'step',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(opt) # print list of methods of object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezunCjNQnXkk"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INi7j-H_nXkm"
   },
   "outputs": [],
   "source": [
    "# create network again just in case\n",
    "model = nn.Sequential()\n",
    "model.add_module('first', nn.Linear(784, 1))\n",
    "model.add_module('second', nn.Sigmoid())\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dShf4FfnXks",
    "outputId": "a460b308-fa41-488b-dc28-1e2650aec717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step #0 | mean loss = 0.821\n",
      "step #10 | mean loss = 0.431\n",
      "step #20 | mean loss = 0.237\n",
      "step #30 | mean loss = 0.180\n",
      "step #40 | mean loss = 0.152\n",
      "step #50 | mean loss = 0.138\n",
      "step #60 | mean loss = 0.117\n",
      "step #70 | mean loss = 0.105\n",
      "step #80 | mean loss = 0.102\n",
      "step #90 | mean loss = 0.104\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # sample 256 random images\n",
    "    ix = np.random.randint(0, len(X_train), 256)\n",
    "    x_batch = torch.tensor(X_train[ix], dtype=torch.float32)\n",
    "    y_batch = torch.tensor(y_train[ix], dtype=torch.float32)\n",
    "\n",
    "    # predict probabilities\n",
    "    y_predicted = model(x_batch)[:,0] # YOUR CODE\n",
    "\n",
    "    assert y_predicted.dim(\n",
    "    ) == 1, \"did you forget to select first column with [:, 0]\"\n",
    "\n",
    "    crossentropy =  y_batch * torch.log(y_predicted) + (1 - y_batch) * torch.log(1 - y_predicted)# YOUR CODE\n",
    "    # compute loss, just like before\n",
    "    loss =  (torch.mean(-crossentropy))# YOUR CODE\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Adam step\n",
    "    opt.step()\n",
    "\n",
    "    # clear gradients\n",
    "    opt.zero_grad()\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"step #%i | mean loss = %.3f\" % (i, np.mean(history[-10:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWfzQC-CnXk6"
   },
   "source": [
    "__Debugging tips:__\n",
    "* make sure your model predicts probabilities correctly. Just print them and see what's inside.\n",
    "* don't forget _minus_ sign in the loss function! It's a mistake 99% ppl do at some point.\n",
    "* make sure you zero-out gradients after each step. Srsly:)\n",
    "* In general, pytorch's error messages are quite helpful, read 'em before you google 'em.\n",
    "* if you see nan/inf, print what happens at each iteration to find our where exactly it occurs.\n",
    "  * If loss goes down and then turns nan midway through, try smaller learning rate. (Our current loss formula is unstable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gj1rnTfInXk8"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Let's see how our model performs on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLC_UWOTnXk-",
    "outputId": "788e4086-cb4f-4e1d-d063-8d2c45ecbc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False  True  True False  True False  True\n",
      "  True False  True False  True False  True False  True  True False False\n",
      "  True  True  True  True False False  True False  True  True  True False\n",
      "  True False  True False False  True  True  True  True False False  True\n",
      " False False  True  True  True  True False  True False  True False  True\n",
      "  True False  True  True False False False False False False False  True\n",
      "  True False  True False False  True  True  True False  True False  True\n",
      "  True False False False  True  True  True  True  True  True  True  True\n",
      "  True False  True False  True  True False  True False  True False  True\n",
      " False  True False False  True False False False False False  True False\n",
      "  True False  True  True  True  True  True  True False  True False  True\n",
      " False False False False  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True False  True False  True  True  True False\n",
      "  True False False  True False  True  True  True False False  True False\n",
      " False False False False  True  True False False False False False  True\n",
      "  True False False  True  True  True  True False  True False False  True\n",
      " False  True False False False  True False  True False  True  True  True\n",
      "  True  True False False  True False False False False False False  True\n",
      " False  True  True False False  True False False  True False  True  True\n",
      " False  True  True False  True  True  True  True False  True  True False\n",
      " False  True  True  True False False  True False  True False False  True\n",
      " False  True  True False False  True False False  True False  True False\n",
      " False False  True False False  True  True  True False  True  True False\n",
      " False  True False  True  True  True False  True  True False False  True\n",
      "  True  True  True  True False False  True False  True  True  True False\n",
      " False  True False False  True  True False False  True  True False False\n",
      "  True False  True  True False False False False  True  True  True  True\n",
      " False False False  True False  True False False False  True  True  True\n",
      " False False False  True False False  True False False False False  True\n",
      " False False  True  True  True  True False False  True False False  True\n",
      "  True  True False False False  True  True False  True False False  True\n",
      "  True  True  True  True False  True  True False False  True  True False\n",
      " False False False False  True  True  True  True False  True False False\n",
      " False  True  True  True False False False False  True False False False\n",
      "  True  True  True False False False  True False False False False False\n",
      " False  True False  True False  True  True False  True False False  True\n",
      " False False False  True False  True  True  True  True False  True False\n",
      "  True  True False  True  True False  True  True False  True  True False\n",
      " False False False False False False False False  True  True False  True\n",
      "  True  True  True False False False False  True  True False False  True\n",
      " False False  True False False False  True False  True  True  True  True\n",
      "  True  True  True False  True  True False False  True False  True False\n",
      " False False  True  True  True  True False False False False False  True\n",
      " False  True  True False  True False False False False  True  True False\n",
      " False False  True  True  True  True False  True  True  True  True False\n",
      "  True False False  True False  True  True  True False False  True False\n",
      " False False False False False False False  True False  True  True False\n",
      "  True False  True False False  True False  True False  True  True  True\n",
      "  True False  True False False  True  True  True  True False  True  True\n",
      "  True  True False False False False  True False  True  True False False\n",
      "  True  True False  True  True False  True False False  True  True False\n",
      "  True False False False False False False False  True  True  True False\n",
      "  True  True  True  True False  True False False  True  True  True False\n",
      " False False  True  True  True  True  True  True  True False False False\n",
      "  True False  True False  True  True False False False  True False False\n",
      " False  True  True  True  True False False  True False False False  True\n",
      "  True  True  True False  True False False  True  True  True False  True\n",
      "  True  True False False  True False  True False  True  True  True  True\n",
      "  True False False False False False False False False  True False  True\n",
      " False  True  True  True False False False  True False  True  True  True\n",
      "  True False  True  True False  True False  True  True False  True False\n",
      "  True False  True  True  True False False False  True False  True  True\n",
      " False False  True  True  True  True  True False False False  True False\n",
      " False False False False  True  True False  True  True False False  True\n",
      "  True  True  True  True  True  True False False False False False  True\n",
      "  True False False False  True False False  True  True  True False False\n",
      "  True False  True False  True  True  True False False  True  True  True\n",
      " False False False False  True False False  True  True False  True  True\n",
      " False  True  True False  True False  True False False  True  True False\n",
      " False False False  True  True False False False  True False  True False\n",
      " False  True  True False  True  True False  True  True False False False\n",
      " False  True  True False  True False  True  True False False False False\n",
      " False  True  True  True  True  True False False False  True False  True\n",
      " False  True  True  True False False  True  True  True False  True False\n",
      "  True False  True  True  True  True False False  True False False  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True False  True False  True False False  True False\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      " False]\n",
      "Test accuracy: 0.96692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arcades/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# use your model to predict classes (0 or 1) for all test samples\n",
    "X_test_ = torch.tensor(X_test, dtype = torch.float32)\n",
    "predicted_y_test = model(X_test_)[:,0]\n",
    "predicted_y_test =  (predicted_y_test > 0.5).detach().numpy()# YOUR CODE\n",
    "print(predicted_y_test)\n",
    "\n",
    "assert isinstance(predicted_y_test, np.ndarray), \"please return np array, not %s\" % type(\n",
    "    predicted_y_test)\n",
    "assert predicted_y_test.shape == y_test.shape, \"please predict one class for each test sample\"\n",
    "assert np.in1d(predicted_y_test, y_test).all(), \"please predict class indexes\"\n",
    "\n",
    "accuracy = np.mean(predicted_y_test == y_test)\n",
    "\n",
    "print(\"Test accuracy: %.5f\" % accuracy)\n",
    "assert accuracy > 0.95, \"try training longer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_RuWCK_nXlF"
   },
   "source": [
    "## More about pytorch:\n",
    "* Using torch on GPU and multi-GPU - [link](http://pytorch.org/docs/master/notes/cuda.html)\n",
    "* More tutorials on pytorch - [link](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* Pytorch examples - a repo that implements many cool DL models in pytorch - [link](https://github.com/pytorch/examples)\n",
    "* Practical pytorch - a repo that implements some... other cool DL models... yes, in pytorch - [link](https://github.com/spro/practical-pytorch)\n",
    "* And some more - [link](https://www.reddit.com/r/pytorch/comments/6z0yeo/pytorch_and_pytorch_tricks_for_kaggle/)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "seminar_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
